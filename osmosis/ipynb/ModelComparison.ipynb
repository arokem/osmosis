{
 "metadata": {
  "name": "ModelComparison"
 },
 "nbformat": 3,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os",
      "import osmosis as oz",
      "import osmosis.model as ozm",
      "import osmosis.viz as viz",
      "import osmosis.utils as ozu",
      "import osmosis.volume as ozv",
      "reload(ozm)",
      "reload(ozu)",
      "",
      "data_path = os.path.split(oz.__file__)[0] + '/data/'",
      "",
      "dwi1 = '0005_01_DTI_2mm_150dir_2x_b2000_aligned_trilin.nii.gz'",
      "dwi2 = '0007_01_DTI_2mm_150dir_2x_b2000_aligned_trilin.nii.gz'",
      "",
      "bvecs1 = '0005_01_DTI_2mm_150dir_2x_b2000_aligned_trilin.bvecs'",
      "bvecs2 = '0007_01_DTI_2mm_150dir_2x_b2000_aligned_trilin.bvecs'",
      "",
      "bvals1 = '0005_01_DTI_2mm_150dir_2x_b2000_aligned_trilin.bvals'",
      "bvals2 = '0007_01_DTI_2mm_150dir_2x_b2000_aligned_trilin.bvals'",
      "",
      "# If you want to choose some collection of voxels and analyze there: ",
      "mask_array = np.zeros((81, 106, 76))",
      "mask_array[39:42,39:42,39:42] = 1",
      "",
      "# These are based on the calculations in GetADandRD",
      "AD=1.4291",
      "RD=0.3507",
      "",
      "",
      "CanonicalTensorModel1 = ozm.CanonicalTensorModel(data_path + dwi1,",
      "                                 data_path + bvecs1,",
      "                                 data_path + bvals1,",
      "                                 #mask=data_path + 'brainMask.nii.gz',",
      "                                 mode='log',",
      "                                 mask=mask_array,",
      "                                 radial_diffusivity=RD,",
      "                                 axial_diffusivity=AD,",
      "                                 #over_sample=246",
      "                                 ) ",
      "",
      "CanonicalTensorModel2 = ozm.CanonicalTensorModel(data_path + dwi2,",
      "                                 data_path + bvecs2,",
      "                                 data_path + bvals1,",
      "                                 #mask=data_path + 'brainMask.nii.gz',",
      "                                 mask=mask_array,",
      "                                 radial_diffusivity=RD,",
      "                                 axial_diffusivity=AD,",
      "                                 #over_sample=246",
      "                                    ) ",
      "",
      "",
      "MultiTensorModel = ozm.MultiCanonicalTensorModel(data_path + dwi1,",
      "                                     data_path + bvecs1,",
      "                                     data_path + bvals1,",
      "                                     params_file=data_path + 'MultiCanonicalTensorCombined_fittosig.nii.gz',",
      "                                     mask=data_path + 'brainMask.nii.gz',",
      "                                     #mask=mask_array,",
      "                                     radial_diffusivity=RD,",
      "                                     axial_diffusivity=AD) ",
      "",
      "MultiTensorModel = ozm.MultiCanonicalTensorModel(data_path + dwi1,",
      "                                     data_path + bvecs1,",
      "                                     data_path + bvals1,",
      "                                     params_file=data_path + 'MultiCanonicalTensorCombined_fittosig.nii.gz',",
      "                                     mask=data_path + 'brainMask.nii.gz',",
      "                                     #mask=mask_array,",
      "                                     radial_diffusivity=RD,",
      "                                     axial_diffusivity=AD) ",
      "",
      "",
      "# These will be used to compute the signal_rmse for relative comparison:",
      "TM1 = ozm.TensorModel(data_path + dwi1, ",
      "                      data_path + bvecs1, ",
      "                      data_path + bvals1, ",
      "                      mask=data_path + 'brainMask.nii.gz',",
      "                      #mask=mask_array,",
      "                      )",
      "",
      "",
      "TM2 = ozm.TensorModel(data_path + dwi2, ",
      "                      data_path + bvecs2, ",
      "                      data_path + bvals2,",
      "                      mask=data_path + 'brainMask.nii.gz',",
      "                      #mask=mask_array,",
      "                      )"
     ],
     "language": "python",
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-1-f9cdea0a88b6>, line 35)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f9cdea0a88b6>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    mask=mask_array,\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "source": [
      "Let's look at the basis set we are using here. Here are two elements of this basis set, which are quite similar in terms of the signal they predict:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig1 = viz.sig_in_points(CanonicalTensorModel1.bvecs[:, CanonicalTensorModel1.b_idx], CanonicalTensorModel1.rotations[7], ",
      "                         r_from_val=True)",
      "",
      "fig2 = viz.sig_in_points(CanonicalTensorModel1.bvecs[:, CanonicalTensorModel1.b_idx], CanonicalTensorModel1.rotations[8], ",
      "                         r_from_val=True)",
      "",
      "bvec1 = CanonicalTensorModel1.bvecs[:,CanonicalTensorModel1.b_idx][:,7]",
      "bvec2 = CanonicalTensorModel1.bvecs[:,CanonicalTensorModel1.b_idx][:,8]"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "source": [
      "And are quite similar in terms of their orientation in 3-space: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()",
      "ax = fig.add_subplot(1,1,1, projection='3d')",
      "ax.plot3D([0, bvec1[0]], [0, bvec1[1]], [0, bvec1[2]], '->')",
      "ax.plot3D([0, bvec2[0]], [0, bvec2[1]], [0, bvec2[2]], '-<')",
      "",
      "ax.set_xlim([-1,1])",
      "ax.set_ylim([-1,1])",
      "ax.set_zlim([-1,1])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "source": [
      "Let's get the data fit and look at some random voxel: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = (40,40,40)",
      "ax = viz.quick_ax()",
      "ax.plot(CanonicalTensorModel1.fit[i])",
      "ax.plot(CanonicalTensorModel1.signal[i])",
      "",
      "ax = viz.quick_ax()",
      "ax.scatter(CanonicalTensorModel1.signal[i], CanonicalTensorModel1.fit[i])",
      "",
      "ozu.coeff_of_determination(CanonicalTensorModel1.fit[40,40,40], TM2.signal[40,40,40])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = (40,40,40)",
      "ax = viz.quick_ax()",
      "ax.plot(MultiTensorModel.fit[i])",
      "ax.plot(MultiTensorModel.signal[i])",
      "",
      "ax = viz.quick_ax()",
      "ax.scatter(MultiTensorModel.signal[i], MultiTensorModel.fit[i])",
      "",
      "ozu.coeff_of_determination(MultiTensorModel.fit[40,40,40], TM2.signal[40,40,40])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = (40,40,40)",
      "ax = viz.quick_ax()",
      "ax.plot(TM1.fit[i])",
      "ax.plot(TM1.signal[i])",
      "",
      "ax = viz.quick_ax()",
      "ax.scatter(TM1.signal[i], TM1.fit[i])",
      "",
      "ozu.coeff_of_determination(TM1.fit[40,40,40], TM2.signal[40,40,40])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "basis_func = CanonicalTensorModel.rotations[CanonicalTensorModel.model_params[i][0]]"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.scatter_density(CanonicalTensorModel.model_params[CanonicalTensorModel.mask][:,1],",
      "                          CanonicalTensorModel.model_params[CanonicalTensorModel.mask][:,2]) ",
      "",
      "fig.set_size_inches([12,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.mosaic(CanonicalTensorModel.model_params[:,:,:,1].T, cmap=matplotlib.cm.bone_r)",
      "fig.set_size_inches([15,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.mosaic(CanonicalTensorModel.model_params[:,:,:,2].T, cmap=matplotlib.cm.bone_r)",
      "fig.set_size_inches([15,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ax = viz.quick_ax()",
      "h = ax.hist(CanonicalTensorModel.RMSE[~np.isnan(CanonicalTensorModel.RMSE)], bins=1000, histtype='step')"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.mosaic(CanonicalTensorModel.RMSE.T, cmap=matplotlib.cm.bone_r, vmax=50)",
      "fig.set_size_inches([15,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.mosaic(MultiTensorModel.RMSE.T, cmap=matplotlib.cm.bone_r, vmax=50)",
      "fig.set_size_inches([15,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "signal_rmse = np.nan * np.ones(TM1.shape[:3])",
      "signal_rmse[TM1.mask] = ozu.rmse(TM1._flat_signal, TM2._flat_signal)",
      "",
      "",
      "canon_tensor_rmse = np.nan * np.ones(TM1.shape[:3])",
      "tensor_rmse = np.nan * np.ones(TM1.shape[:3])",
      "multi_tensor_rmse = np.nan * np.ones(TM1.shape[:3])",
      "",
      "# These are all our models so far: ",
      "canon_tensor_rmse[CanonicalTensorModel.mask] = ozu.rmse(CanonicalTensorModel.fit[CanonicalTensorModel.mask], TM2._flat_signal)",
      "tensor_rmse[CanonicalTensorModel.mask] = ozu.rmse(TM1.fit[CanonicalTensorModel.mask], TM2._flat_signal)",
      "multi_tensor_rmse[CanonicalTensorModel.mask] = ozu.rmse(MultiTensorModel.fit[CanonicalTensorModel.mask], TM2._flat_signal) ",
      "",
      "# This is a \"null model\" - every voxel is a sphere with the average signal:",
      "sphere_rmse = np.nan * np.ones(TM1.shape[:3])",
      "sphere_rmse[TM1.mask] = ozu.rmse(np.mean(TM1._flat_signal,-1).reshape(1,TM1._flat_signal.shape[0]).T + ",
      "                                 np.zeros(TM1._flat_signal.shape), TM2._flat_signal)",
      "",
      "rel_can_rmse = canon_tensor_rmse/signal_rmse",
      "rel_ten_rmse = tensor_rmse/signal_rmse",
      "rel_mul_rmse = multi_tensor_rmse/signal_rmse",
      "rel_sphere_rmse = sphere_rmse/signal_rmse"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(viz)",
      "ax_all = viz.quick_ax()",
      "colors = ['r', 'b', 'g','k']",
      "for relative_rmse, label, n_bins, c  in zip([rel_sphere_rmse, rel_ten_rmse, rel_can_rmse], ",
      "                          ['Sphere', 'Tensor', 'Canonical Tensor + Sphere'],",
      "                          [100, 1000, 100],",
      "                           colors):",
      "    relative_rmse[np.where(relative_rmse==inf)] = np.nan",
      "    ax = viz.quick_ax()",
      "    ax.set_xlim([0,2])",
      "    ax.get_figure().set_size_inches([10,5])",
      "    ax.hist(relative_rmse[~np.isnan(relative_rmse)], bins=n_bins, histtype='step', color=c)",
      "    ax_all.hist(relative_rmse[~np.isnan(relative_rmse)], bins=n_bins, histtype='step', label=label, color=c)",
      "",
      "ax_all.set_xlim([0,2])",
      "ax_all.get_figure().set_size_inches([10,5])",
      "ax_all.legend()",
      "ax_all.set_xlabel('$RMSE_{relative}$')",
      "ax_all.set_ylabel('# voxels')",
      "",
      "",
      "colors = ['b', 'g','k']",
      "ax_all = viz.quick_ax()",
      "for relative_rmse, label, n_bins, c  in zip([rel_ten_rmse, rel_can_rmse, rel_mul_rmse], ",
      "                          ['Tensor', 'Canonical Tensor + Sphere', 'Two Canonicals + sphere'],",
      "                          [1000, 100,  100],",
      "                           colors):",
      "    relative_rmse[np.where(relative_rmse==inf)] = np.nan",
      "    ax = viz.quick_ax()",
      "    ax.set_xlim([0,2])",
      "    ax.get_figure().set_size_inches([10,5])",
      "    ax.hist(relative_rmse[~np.isnan(relative_rmse)], bins=n_bins, histtype='step', color=c)",
      "    ax_all.hist(relative_rmse[~np.isnan(relative_rmse)], bins=n_bins, histtype='step', label=label, color=c)",
      "",
      "ax_all.set_xlim([0,2])",
      "ax_all.get_figure().set_size_inches([10,5])",
      "    ",
      "ax_all.legend()",
      "np.sum(np.isnan(rel_sphere_rmse)), np.sum(np.isnan(rel_ten_rmse)), np.sum(np.isnan(rel_can_rmse)), np.sum(np.isnan(rel_mul_rmse))"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T1 = ozv.resample_volume(data_path + 'FP_t1.nii.gz', data_path + dwi1).get_data()"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.mosaic(T1.T, cmap=matplotlib.cm.bone, cbar=False)",
      "rel_diff = rel_can_rmse - rel_ten_rmse",
      "rel_diff[np.isinf(rel_diff)] = np.nan",
      "rel_diff[np.logical_and(rel_diff>-0.2, rel_diff<0.2)] = np.nan",
      "fig= viz.mosaic(rel_diff.T,fig=fig, vmin=-0.5, vmax=0.5, cmap=matplotlib.cm.RdBu_r)",
      "fig.set_size_inches([17,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rel_diff = rel_sphere_rmse - rel_ten_rmse",
      "rel_diff[np.isinf(rel_diff)] = np.nan",
      "fig= viz.mosaic(rel_diff.T, vmin=-1, vmax=1)",
      "fig.set_size_inches([17,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rel_diff = rel_sphere_rmse - rel_can_rmse",
      "rel_diff[np.isinf(rel_diff)] = np.nan",
      "fig= viz.mosaic(rel_diff.T, vmin=-1, vmax=1)",
      "fig.set_size_inches([17,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.scatter_density(TM1.fractional_anisotropy[TM1.mask], rel_diff[TM1.mask])",
      "fig.set_size_inches([12,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.scatter_density(TM1.fractional_anisotropy[TM1.mask], CanonicalTensorModel.model_params[TM1.mask,1])",
      "fig.set_size_inches([12,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.scatter_density(TM1.fractional_anisotropy[TM1.mask], CanonicalTensorModel.model_params[TM1.mask,2])",
      "fig.set_size_inches([12,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.scatter_density(TM1.mean_diffusivity[TM1.mask], CanonicalTensorModel.model_params[TM1.mask,1])",
      "fig.set_size_inches([10,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = viz.scatter_density(TM1.mean_diffusivity[TM1.mask], CanonicalTensorModel.model_params[TM1.mask,2])",
      "fig.set_size_inches([10,10])"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "source": [
      "3.       How well do we fit by isotropic plus two anisotropic canonical (7 parameter fit)",
      "",
      "",
      "4.       What are the spatial properties of these fits?",
      "",
      "5.       What are the effects of different b values?",
      "",
      " ",
      " ",
      "We should be able to fit at each bvec direction (or possibly interpolated on the sphere to twice the resolution)",
      "We should be able to fit the weights to each bvec direction to all the voxels at once for some efficiencies.",
      "We should ask whether there is an inverse relationship between the two weights (surely there will be)",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      ""
     ],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}